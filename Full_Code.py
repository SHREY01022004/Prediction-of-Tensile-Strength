# -*- coding: utf-8 -*-
"""Ek aur file.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NTw2KZBzM1m13t20x_VdOmic4O4OXpfd

#Dataset Loading
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/BTP Dataset - Sheet1.csv', header=0, skiprows=[1])

df.columns = ['Sample', 'Time (s)', 'Extension (mm)', 'Load (kN)', 'Strain (mm/mm)', 'Stress (MPa)']

print(df.head())

print(df.info())

print(df.describe())

print(df['Sample'].unique())

"""#Data Analysis"""

numerical_cols = ['Time (s)', 'Extension (mm)', 'Load (kN)', 'Strain (mm/mm)', 'Stress (MPa)']

plot_style = {
    'font.family': 'serif',
    'font.size': 26,
    'axes.linewidth': 3,
    'xtick.major.width': 2,
    'xtick.major.size': 8,
    'ytick.major.width': 2,
    'ytick.major.size': 8,
    'font.weight': 'bold'
}
plt.rcParams.update(plot_style)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

for col in numerical_cols:
    fig, ax = plt.subplots(figsize=(15, 12))

    sns.boxplot(x='Sample', y=col, data=df, ax=ax, palette="viridis", linewidth=2.5)

    for i, artist in enumerate(ax.artists):
        artist.set_edgecolor('black')
        artist.set_linewidth(3)

    for i, line in enumerate(ax.lines):
        line.set_color('black')
        line.set_linewidth(3)

    ax.set_xlabel(None)
    ax.set_ylabel(col, fontweight='bold', fontsize=44)

    ax.tick_params(axis='x', rotation=45, labelsize=40)
    ax.tick_params(axis='y', labelsize=40)

    for label in ax.get_xticklabels():
        label.set_fontweight('bold')

    plt.tight_layout()

    safe_col_name = col.replace(' ', '_').replace('(', '').replace(')', '').replace('/', '_')
    file_name = f"final_box_plot_{safe_col_name}_bolder_lines.tif"
    plt.savefig(file_name, format='tiff', dpi=300, bbox_inches='tight')
    plt.show()

    plt.close(fig)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

plot_style = {
    'font.family': 'serif',
    'font.weight': 'bold'
}
plt.rcParams.update(plot_style)

for col in numerical_cols:
    fig, ax = plt.subplots(figsize=(15, 12))

    sns.violinplot(x='Sample', y=col, data=df, ax=ax, palette="viridis")

    for pc in ax.collections:
        pc.set_edgecolor('black')
        pc.set_linewidth(3)

    for line in ax.lines:
        line.set_color('black')
        line.set_linewidth(3)

    ax.set_xlabel(None)
    ax.set_ylabel(col, fontweight='bold', fontsize=44)

    ax.tick_params(axis='x', rotation=45, labelsize=40)
    ax.tick_params(axis='y', labelsize=40)

    for label in ax.get_xticklabels():
        label.set_fontweight('bold')

    plt.tight_layout()

    safe_col_name = col.replace(' ', '_').replace('(', '').replace(')', '').replace('/', '_')
    file_name = f"final_violin_plot_{safe_col_name}_bolder_lines.tif"
    plt.savefig(file_name, format='tiff', dpi=300, bbox_inches='tight')
    plt.show()

    plt.close(fig)

print("All violin plots have been saved as separate .tif files with bolder lines.")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import itertools

plot_style = {
    'font.family': 'serif',
    'font.weight': 'bold'
}
plt.rcParams.update(plot_style)

numerical_cols = ['Time (s)', 'Extension (mm)', 'Load (kN)', 'Strain (mm/mm)', 'Stress (MPa)']
all_pairs = list(itertools.permutations(numerical_cols, 2))

def plot_and_save_horizontal_group(plot_pairs_chunk, file_suffix):
    num_plots = len(plot_pairs_chunk)
    fig, axes = plt.subplots(nrows=1, ncols=num_plots, figsize=(15 * num_plots, 15))

    if num_plots == 1:
        axes = [axes]

    for i, (x_col, y_col) in enumerate(plot_pairs_chunk):
        ax = axes[i]
        sns.scatterplot(data=df, x=x_col, y=y_col, hue='Sample', ax=ax, s=80, alpha=0.7, palette='viridis')

        ax.set_xlabel(x_col, fontsize=44, fontweight='bold')
        ax.set_ylabel(y_col, fontsize=44, fontweight='bold')
        ax.grid(True)
        ax.tick_params(axis='both', which='major', labelsize=40)

        legend = ax.legend(title='Sample', markerscale=3, fontsize=32)
        plt.setp(legend.get_title(), fontsize=34, fontweight='bold')

        for label in (ax.get_xticklabels() + ax.get_yticklabels()):
            label.set_fontweight('bold')

    plt.tight_layout()
    plt.savefig(f'pair_plots_{file_suffix}.tif', format='tiff', dpi=300, bbox_inches='tight')
    plt.show()

# Generate the 4 separate image files
plot_and_save_horizontal_group(all_pairs[0:5], "part1")
plot_and_save_horizontal_group(all_pairs[5:10], "part2")
plot_and_save_horizontal_group(all_pairs[10:15], "part3")
plot_and_save_horizontal_group(all_pairs[15:20], "part4")

print("All pair plots have been saved into 4 separate .tif files.")

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load dataset
file_path = "BTP Dataset - Sheet1.csv"
df = pd.read_csv(file_path)

# Remove the row with units and reset index
df_clean = df.drop(0).reset_index(drop=True)

# Convert relevant columns to numeric
numeric_cols = ["Time", "Extension", "Load", "Tensile strain (Extension)", "Tensile stress"]
for col in numeric_cols:
    df_clean[col] = pd.to_numeric(df_clean[col], errors="coerce")

# Drop unnecessary column
df_clean = df_clean.drop(columns=["Unnamed: 0"])

# Drop rows with NaN values in numeric columns
df_clean = df_clean.dropna(subset=numeric_cols)

# Plot pairplot with histograms on diagonal
sns.pairplot(df_clean[numeric_cols], diag_kind="hist")
plt.show()

"""#Train Test Split"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
import numpy as np

# Clip negative values to zero if they are noise
df[['Extension (mm)', 'Load (kN)', 'Strain (mm/mm)', 'Stress (MPa)']] = df[['Extension (mm)', 'Load (kN)', 'Strain (mm/mm)', 'Stress (MPa)']].clip(lower=0)

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df['Sample_encoded'] = le.fit_transform(df['Sample'])

X = df[['Time (s)', 'Extension (mm)', 'Load (kN)', 'Sample_encoded']]
y = df[['Strain (mm/mm)', 'Stress (MPa)']]

test_sizes = [0.4, 0.3, 0.2, 0.1]

splits = {}

for test_size in test_sizes:
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=42,
        stratify=df['Sample']  # Stratify by Sample to maintain distribution
    )

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    splits[f'train{int((1-test_size)*100)}_test{int(test_size*100)}'] = {
        'X_train': X_train, 'X_test': X_test,
        'X_train_scaled': X_train_scaled, 'X_test_scaled': X_test_scaled,
        'y_train': y_train, 'y_test': y_test
    }

    print(f"\nSplit: {int((1-test_size)*100)}/{int(test_size*100)}")
    print("X_train shape:", X_train.shape)
    print("X_test shape:", X_test.shape)
    print("y_train shape:", y_train.shape)
    print("y_test shape:", y_test.shape)
    print("Train Sample distribution:\n", X_train['Sample_encoded'].value_counts(normalize=True))
    print("Test Sample distribution:\n", X_test['Sample_encoded'].value_counts(normalize=True))

"""#Training on ML models"""

pip install keras-tcn

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.ensemble import RandomForestRegressor, VotingRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.multioutput import MultiOutputRegressor
from sklearn.svm import SVR
from sklearn.ensemble import StackingRegressor
import matplotlib.pyplot as plt

X = df[['Time (s)', 'Extension (mm)', 'Load (kN)', 'Sample_encoded']]
y = df[['Strain (mm/mm)', 'Stress (MPa)']]

test_sizes = [0.4, 0.3, 0.2, 0.1]
splits = {}
for test_size in test_sizes:
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=df['Sample'])
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    splits[f'train{int((1-test_size)*100)}_test{int(test_size*100)}'] = {
        'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test,
        'X_train_scaled': X_train_scaled, 'X_test_scaled': X_test_scaled
    }

def evaluate_model(model, X_test, y_test, model_name, split_name):
    y_pred = model.predict(X_test)
    r2 = np.mean([r2_score(y_test.iloc[:, i], y_pred[:, i]) for i in range(y_test.shape[1])])
    rmse = np.mean([np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred[:, i])) for i in range(y_test.shape[1])])
    mae = np.mean([mean_absolute_error(y_test.iloc[:, i], y_pred[:, i]) for i in range(y_test.shape[1])])
    print(f"{model_name} on {split_name}: R2={r2:.4f}, RMSE={rmse:.4f}, MAE={mae:.4f}")
    return {'model': model_name, 'split': split_name, 'R2': r2, 'RMSE': rmse, 'MAE': mae}, y_pred

def prepare_sequences(X_df, y_df, df_group):
    sequences_X = []
    sequences_y = []
    max_len = 0
    for sample in df_group['Sample_encoded'].unique():
        idx = df_group['Sample_encoded'] == sample
        seq_X = X_df[idx].values
        seq_y = y_df[idx].values
        sequences_X.append(seq_X)
        sequences_y.append(seq_y)
        max_len = max(max_len, len(seq_X))
    # Pad sequences
    X_padded = np.array([np.pad(seq, ((0, max_len - len(seq)), (0,0)), mode='constant') for seq in sequences_X])
    y_padded = np.array([np.pad(seq, ((0, max_len - len(seq)), (0,0)), mode='constant') for seq in sequences_y])
    return X_padded, y_padded, max_len

"""##Random Forest Regressor"""

split_name = 'train70_test30'
data = splits[split_name]
X_train_scaled = data['X_train_scaled']
X_test_scaled = data['X_test_scaled']
y_train = data['y_train']
y_test = data['y_test']

from sklearn.ensemble import RandomForestRegressor

rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X_train_scaled, y_train)

# Evaluate
metrics, y_pred = evaluate_model(rf_model, X_test_scaled, y_test, 'RandomForest', split_name)
print(metrics)

# Residual plot
residuals = y_test.values - y_pred

fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(20, 30))
fig.suptitle('RandomForest Residuals', fontsize=32, y=1.0)

axes[0].scatter(y_pred[:, 0], residuals[:, 0])
axes[0].set_title('Strain Residuals')
axes[0].set_xlabel('Predicted Strain')
axes[0].set_ylabel('Residuals')
axes[0].grid(True)
axes[0].axhline(y=0, color='r', linestyle='--')

axes[1].scatter(y_pred[:, 1], residuals[:, 1])
axes[1].set_title('Stress Residuals')
axes[1].set_xlabel('Predicted Stress')
axes[1].set_ylabel('Residuals')
axes[1].grid(True)
axes[1].axhline(y=0, color='r', linestyle='--')

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

test_df = y_test.copy()
test_df['pred_strain'] = y_pred[:, 0]
test_df['pred_stress'] = y_pred[:, 1]

test_df.sort_values('Tensile strain (mm/mm)', inplace=True)

fig, ax = plt.subplots(figsize=(15, 10))

ax.plot(test_df['Tensile strain (mm/mm)'], test_df['Tensile stress (MPa)'],
        label='Actual', linewidth=3)
ax.plot(test_df['pred_strain'], test_df['pred_stress'],
        label='Predicted', linestyle='--', linewidth=3)

ax.set_title('Stress-Strain Graph: Actual vs Predicted')
ax.set_xlabel('Strain (mm/mm)')
ax.set_ylabel('Stress (MPa)')

ax.legend()
ax.grid(True)

plt.show()

"""##Decision Tree"""

from sklearn.tree import DecisionTreeRegressor

dt_model = DecisionTreeRegressor(random_state=42)
dt_model.fit(X_train_scaled, y_train)

metrics, y_pred = evaluate_model(dt_model, X_test_scaled, y_test, 'DecisionTree', split_name)
print(metrics)

# Residual plot
residuals = y_test.values - y_pred

fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(20, 30))
fig.suptitle('Decision Tree Residuals', fontsize=32, y=1.0)

axes[0].scatter(y_pred[:, 0], residuals[:, 0])
axes[0].set_title('Strain Residuals')
axes[0].set_xlabel('Predicted Strain')
axes[0].set_ylabel('Residuals')
axes[0].grid(True)
axes[0].axhline(y=0, color='r', linestyle='--')

axes[1].scatter(y_pred[:, 1], residuals[:, 1])
axes[1].set_title('Stress Residuals')
axes[1].set_xlabel('Predicted Stress')
axes[1].set_ylabel('Residuals')
axes[1].grid(True)
axes[1].axhline(y=0, color='r', linestyle='--')

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

test_df = y_test.copy()
test_df['pred_strain'] = y_pred[:, 0]
test_df['pred_stress'] = y_pred[:, 1]

test_df.sort_values('Tensile strain (mm/mm)', inplace=True)

fig, ax = plt.subplots(figsize=(15, 10))

ax.plot(test_df['Tensile strain (mm/mm)'], test_df['Tensile stress (MPa)'],
        label='Actual', linewidth=3)
ax.plot(test_df['pred_strain'], test_df['pred_stress'],
        label='Predicted', linestyle='--', linewidth=3)

ax.set_title('Stress-Strain Graph: Actual vs Predicted')
ax.set_xlabel('Strain (mm/mm)')
ax.set_ylabel('Stress (MPa)')

ax.legend()
ax.grid(True)

plt.show()

"""##Support Vector Regressor"""

from sklearn.svm import SVR
from sklearn.multioutput import MultiOutputRegressor

svm_model = MultiOutputRegressor(SVR())
svm_model.fit(X_train_scaled, y_train)

metrics, y_pred = evaluate_model(svm_model, X_test_scaled, y_test, 'SVM', split_name)
print(metrics)

# Residual plot
residuals = y_test.values - y_pred

fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(20, 30))
fig.suptitle('SVM Residuals', fontsize=32, y=1.0)

axes[0].scatter(y_pred[:, 0], residuals[:, 0])
axes[0].set_title('Strain Residuals')
axes[0].set_xlabel('Predicted Strain')
axes[0].set_ylabel('Residuals')
axes[0].grid(True)
axes[0].axhline(y=0, color='r', linestyle='--')

axes[1].scatter(y_pred[:, 1], residuals[:, 1])
axes[1].set_title('Stress Residuals')
axes[1].set_xlabel('Predicted Stress')
axes[1].set_ylabel('Residuals')
axes[1].grid(True)
axes[1].axhline(y=0, color='r', linestyle='--')

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

test_df = y_test.copy()
test_df['pred_strain'] = y_pred[:, 0]
test_df['pred_stress'] = y_pred[:, 1]

# Sort by true strain for plotting
test_df.sort_values('Tensile strain (mm/mm)', inplace=True)

fig, ax = plt.subplots(figsize=(15, 10))

ax.plot(test_df['Tensile strain (mm/mm)'], test_df['Tensile stress (MPa)'],
        label='Actual', linewidth=3)
ax.plot(test_df['pred_strain'], test_df['pred_stress'],
        label='Predicted', linestyle='--', linewidth=3)

ax.set_title('Stress-Strain Graph: Actual vs Predicted')
ax.set_xlabel('Strain (mm/mm)')
ax.set_ylabel('Stress (MPa)')

ax.legend()
ax.grid(True)

plt.show()

"""##KNN"""

from sklearn.neighbors import KNeighborsRegressor

knn_model = KNeighborsRegressor()
knn_model.fit(X_train_scaled, y_train)

metrics, y_pred = evaluate_model(knn_model, X_test_scaled, y_test, 'KNN', split_name)
print(metrics)

test_df = y_test.copy()
test_df['pred_strain'] = y_pred[:, 0]
test_df['pred_stress'] = y_pred[:, 1]

test_df.sort_values('Tensile strain (mm/mm)', inplace=True)

fig, ax = plt.subplots(figsize=(15, 10))

ax.plot(test_df['Tensile strain (mm/mm)'], test_df['Tensile stress (MPa)'],
        label='Actual', linewidth=3)
ax.plot(test_df['pred_strain'], test_df['pred_stress'],
        label='Predicted', linestyle='--', linewidth=3)

ax.set_title('Stress-Strain Graph: Actual vs Predicted')
ax.set_xlabel('Strain (mm/mm)')
ax.set_ylabel('Stress (MPa)')

ax.legend()
ax.grid(True)

plt.show()

"""#Training on DL models

##Data Preprocessing
"""

from sklearn.model_selection import GroupShuffleSplit
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler

test_sizes = [0.4, 0.3, 0.2, 0.1]
splits = {}
for test_size in test_sizes:
    gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=42)
    train_idx, test_idx = next(gss.split(X, y, groups=df['Sample_encoded']))

    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    splits[f'train{int((1-test_size)*100)}_test{int(test_size*100)}'] = {
        'X_train': X_train, 'X_test': X_test,
        'X_train_scaled': X_train_scaled, 'X_test_scaled': X_test_scaled,
        'y_train': y_train, 'y_test': y_test
    }

    print(f"\nSplit: {int((1-test_size)*100)}/{int(test_size*100)}")
    print("Train samples:", X_train['Sample_encoded'].unique())
    print("Test samples:", X_test['Sample_encoded'].unique())

data = splits[split_name]
train_df = pd.concat([data['X_train'], data['y_train']], axis=1)
test_df = pd.concat([data['X_test'], data['y_test']], axis=1)

train_df = train_df.sort_values(['Sample_encoded', 'Time (s)'])
test_df = test_df.sort_values(['Sample_encoded', 'Time (s)'])

def prepare_sequences(X_df, y_df, df_group):
    sequences_X = []
    sequences_y = []
    max_len = 0
    for sample in df_group['Sample_encoded'].unique():
        idx = df_group['Sample_encoded'] == sample
        seq_X = X_df[idx].values
        seq_y = y_df[idx].values
        sequences_X.append(seq_X)
        sequences_y.append(seq_y)
        max_len = max(max_len, len(seq_X))

    X_padded = np.array([np.pad(seq, ((0, max_len - len(seq)), (0,0)), mode='constant') for seq in sequences_X])
    y_padded = np.array([np.pad(seq, ((0, max_len - len(seq)), (0,0)), mode='constant') for seq in sequences_y])
    return X_padded, y_padded, max_len

X_train_seq, y_train_seq, max_len_train = prepare_sequences(
    train_df[['Time (s)', 'Extension (mm)', 'Load (kN)']],
    train_df[['Strain (mm/mm)', 'Stress (MPa)']],
    train_df
)

sequences_X_test = []
sequences_y_test = []
for sample in test_df['Sample_encoded'].unique():
    idx = test_df['Sample_encoded'] == sample
    seq_X = test_df.loc[idx, ['Time (s)', 'Extension (mm)', 'Load (kN)']].values  # Use .loc for safety
    seq_y = test_df.loc[idx, ['Strain (mm/mm)', 'Stress (MPa)']].values
    sequences_X_test.append(seq_X)
    sequences_y_test.append(seq_y)

X_test_padded = np.array([np.pad(seq, ((0, max_len_train - len(seq)), (0,0)), mode='constant') for seq in sequences_X_test])
y_test_padded = np.array([np.pad(seq, ((0, max_len_train - len(seq)), (0,0)), mode='constant') for seq in sequences_y_test])

train_mask = np.any(X_train_seq != 0, axis=2)
X_train_seq_flat_nonpad = X_train_seq[train_mask].reshape(-1, X_train_seq.shape[2])

scaler_seq = StandardScaler()
scaler_seq.fit(X_train_seq_flat_nonpad)

X_train_seq_scaled = scaler_seq.transform(X_train_seq.reshape(-1, X_train_seq.shape[2])).reshape(X_train_seq.shape)
X_test_seq_scaled = scaler_seq.transform(X_test_padded.reshape(-1, X_test_padded.shape[2])).reshape(X_test_padded.shape)

def masked_mse(y_true, y_pred):
    mask = tf.math.not_equal(tf.reduce_sum(y_true, axis=-1), 0)
    y_true_masked = tf.boolean_mask(y_true, mask)
    y_pred_masked = tf.boolean_mask(y_pred, mask)
    return tf.keras.losses.mean_squared_error(y_true_masked, y_pred_masked)

X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_test_reshaped = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

from sklearn.preprocessing import MinMaxScaler
import numpy as np

x_scaler = StandardScaler()
y_scaler = MinMaxScaler()

X_train_scaled = x_scaler.fit_transform(X_train)
X_test_scaled = x_scaler.transform(X_test)

y_train_scaled = y_scaler.fit_transform(y_train)
y_test_scaled = y_scaler.transform(y_test)

X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_test_reshaped = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

def evaluate_scaled(model, X_test, y_test, model_name, split_name, scaler=None):
    if scaler:
        y_pred_scaled = model.predict(X_test)
        y_pred = scaler.inverse_transform(y_pred_scaled)
    else:
        y_pred = model.predict(X_test)

    r2 = np.mean([r2_score(y_test.iloc[:, i], y_pred[:, i]) for i in range(y_test.shape[1])])
    rmse = np.mean([np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred[:, i])) for i in range(y_test.shape[1])])
    mae = np.mean([mean_absolute_error(y_test.iloc[:, i], y_pred[:, i]) for i in range(y_test.shape[1])])
    print(f"{model_name} on {split_name}: R2={r2:.4f}, RMSE={rmse:.4f}, MAE={mae:.4f}")
    return {'model': model_name, 'split': split_name, 'R2': r2, 'RMSE': rmse, 'MAE': mae}, y_pred

"""##ANN"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Bidirectional, GRU
from tcn import TCN

ann_model = Sequential()
ann_model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))
ann_model.add(Dense(32, activation='relu'))
ann_model.add(Dense(2))

ann_model.compile(optimizer='adam', loss='mse', metrics=['mae'])

history = ann_model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)

metrics, y_pred = evaluate_model(ann_model, X_test_scaled, y_test, 'ANN', split_name)
print(metrics)

# Residual plot
residuals = y_test.values - y_pred

fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(20, 30))
fig.suptitle('ANN Residuals', fontsize=32, y=1.0)

axes[0].scatter(y_pred[:, 0], residuals[:, 0])
axes[0].set_title('Strain Residuals')
axes[0].set_xlabel('Predicted Strain')
axes[0].set_ylabel('Residuals')
axes[0].grid(True)
axes[0].axhline(y=0, color='r', linestyle='--')

axes[1].scatter(y_pred[:, 1], residuals[:, 1])
axes[1].set_title('Stress Residuals')
axes[1].set_xlabel('Predicted Stress')
axes[1].set_ylabel('Residuals')
axes[1].grid(True)
axes[1].axhline(y=0, color='r', linestyle='--')

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

# Stress-Strain Graph
test_df = y_test.copy()
test_df['pred_strain'] = y_pred[:, 0]
test_df['pred_stress'] = y_pred[:, 1]
test_df.sort_values('Tensile strain (mm/mm)', inplace=True)
plt.figure(figsize=(8, 6))
plt.plot(test_df['Tensile strain (mm/mm)'], test_df['Tensile stress (MPa)'], label='Actual', alpha=0.7)
plt.plot(test_df['pred_strain'], test_df['pred_stress'], label='Predicted', alpha=0.7, linestyle='--')
plt.title('Stress-Strain Graph: Actual vs Predicted (ANN)')
plt.xlabel('Strain (mm/mm)')
plt.ylabel('Stress (MPa)')
plt.legend()
plt.show()

ann_model = Sequential([
    Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]),
    Dense(32, activation='relu'),
    Dense(2)
])
ann_model.compile(optimizer='adam', loss='mse')
ann_model.fit(X_train_scaled, y_train_scaled, epochs=50, batch_size=32, verbose=0)

metrics_ann, y_pred_ann = evaluate_scaled(ann_model, X_test_scaled, y_test, 'ANN', split_name, scaler=y_scaler)
print(metrics_ann)

test_df_ann = y_test.copy()
test_df_ann['pred_strain'] = y_pred_ann[:, 0]
test_df_ann['pred_stress'] = y_pred_ann[:, 1]
test_df_ann.sort_values('Tensile strain (mm/mm)', inplace=True)

plt.figure(figsize=(8, 6))
plt.plot(test_df_ann['Tensile strain (mm/mm)'], test_df_ann['Tensile stress (MPa)'], label='Actual', color='blue')
plt.plot(test_df_ann['pred_strain'], test_df_ann['pred_stress'], label='Predicted (ANN)', color='red', linestyle='--')
plt.title('Stress-Strain Graph: Actual vs Predicted (ANN)')
plt.xlabel('Strain (mm/mm)')
plt.ylabel('Stress (MPa)')
plt.legend()
plt.grid(True)
plt.show()

"""##LSTM"""

lstm_model = Sequential([
    LSTM(64, activation='tanh', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])),
    Dense(32, activation='relu'),
    Dense(2)
])

lstm_model.compile(optimizer='adam', loss='mse')

lstm_model.fit(X_train_reshaped, y_train_scaled, epochs=50, batch_size=32, verbose=0)

y_pred_scaled = lstm_model.predict(X_test_reshaped)
y_pred_lstm = y_scaler.inverse_transform(y_pred_scaled)

metrics_lstm, _ = evaluate_scaled(lstm_model, X_test_reshaped, y_test, 'LSTM', split_name, scaler=y_scaler)
print(metrics_lstm)

test_df_lstm = y_test.copy()
test_df_lstm['pred_strain'] = y_pred_lstm[:, 0]
test_df_lstm['pred_stress'] = y_pred_lstm[:, 1]
test_df_lstm.sort_values('Tensile strain (mm/mm)', inplace=True)

fig, ax = plt.subplots(figsize=(15, 10))

ax.plot(test_df_lstm['Tensile strain (mm/mm)'], test_df_lstm['Tensile stress (MPa)'],
        label='Actual', color='blue', linewidth=3)
ax.plot(test_df_lstm['pred_strain'], test_df_lstm['pred_stress'],
        label='Predicted (LSTM)', color='red', linestyle='--', linewidth=3)

ax.set_title('Stress-Strain Graph: Actual vs Predicted (LSTM)')
ax.set_xlabel('Strain (mm/mm)')
ax.set_ylabel('Stress (MPa)')

ax.legend()
ax.grid(True)

plt.show()

"""##BiLSTM"""

bilstm_model = Sequential([
    Bidirectional(LSTM(64, activation='tanh'), input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])),
    Dense(32, activation='relu'),
    Dense(2)
])
bilstm_model.compile(optimizer='adam', loss='mse')
bilstm_model.fit(X_train_reshaped, y_train_scaled, epochs=50, batch_size=32, verbose=0)

y_pred_scaled = bilstm_model.predict(X_test_reshaped)
y_pred_bilstm = y_scaler.inverse_transform(y_pred_scaled)

metrics_bilstm, y_pred_bilstm = evaluate_scaled(bilstm_model, X_test_reshaped, y_test, 'BiLSTM', split_name, scaler=y_scaler)
print(metrics_bilstm)

test_df_bilstm = y_test.copy()
test_df_bilstm['pred_strain'] = y_pred_bilstm[:, 0]
test_df_bilstm['pred_stress'] = y_pred_bilstm[:, 1]
test_df_bilstm.sort_values('Tensile strain (mm/mm)', inplace=True)

fig, ax = plt.subplots(figsize=(15, 10))

ax.plot(test_df_bilstm['Tensile strain (mm/mm)'], test_df_bilstm['Tensile stress (MPa)'],
        label='Actual', color='blue', linewidth=3)
ax.plot(test_df_bilstm['pred_strain'], test_df_bilstm['pred_stress'],
        label='Predicted (LSTM)', color='red', linestyle='--', linewidth=3)

ax.set_title('Stress-Strain Graph: Actual vs Predicted (BiLSTM)')
ax.set_xlabel('Strain (mm/mm)')
ax.set_ylabel('Stress (MPa)')

ax.legend()
ax.grid(True)

plt.show()

"""##GRU"""

gru_model = Sequential([
    GRU(64, activation='tanh', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])),
    Dense(32, activation='relu'),
    Dense(2)
])
gru_model.compile(optimizer='adam', loss='mse')
gru_model.fit(X_train_reshaped, y_train_scaled, epochs=50, batch_size=32, verbose=0)

y_pred_scaled = gru_model.predict(X_test_reshaped)
y_pred_gru = y_scaler.inverse_transform(y_pred_scaled)

metrics_gru, y_pred_gru = evaluate_scaled(gru_model, X_test_reshaped, y_test, 'GRU', split_name, scaler=y_scaler)
print(metrics_gru)

test_df_gru = y_test.copy()
test_df_gru['pred_strain'] = y_pred_gru[:, 0]
test_df_gru['pred_stress'] = y_pred_gru[:, 1]
test_df_gru.sort_values('Tensile strain (mm/mm)', inplace=True)

plt.figure(figsize=(8, 6))
plt.plot(test_df_gru['Tensile strain (mm/mm)'], test_df_gru['Tensile stress (MPa)'], label='Actual', color='blue')
plt.plot(test_df_gru['pred_strain'], test_df_gru['pred_stress'], label='Predicted (GRU)', color='red', linestyle='--')
plt.title('Stress-Strain Graph: Actual vs Predicted (GRU)')
plt.xlabel('Strain (mm/mm)')
plt.ylabel('Stress (MPa)')
plt.legend()
plt.grid(True)
plt.show()

"""##TCN"""

tcn_model = Sequential([
    TCN(64, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])),
    Dense(32, activation='relu'),
    Dense(2)
])
tcn_model.compile(optimizer='adam', loss='mse')
tcn_model.fit(X_train_reshaped, y_train_scaled, epochs=50, batch_size=32, verbose=0)

y_pred_scaled = tcn_model.predict(X_test_reshaped)
y_pred_tcn = y_scaler.inverse_transform(y_pred_scaled)

metrics_tcn, y_pred_tcn = evaluate_scaled(tcn_model, X_test_reshaped, y_test, 'TCN', split_name, scaler=y_scaler)
print(metrics_tcn)

test_df_tcn = y_test.copy()
test_df_tcn['pred_strain'] = y_pred_tcn[:, 0]
test_df_tcn['pred_stress'] = y_pred_tcn[:, 1]
test_df_tcn.sort_values('Tensile strain (mm/mm)', inplace=True)

plt.figure(figsize=(8, 6))
plt.plot(test_df_tcn['Tensile strain (mm/mm)'], test_df_tcn['Tensile stress (MPa)'], label='Actual', color='blue')
plt.plot(test_df_tcn['pred_strain'], test_df_tcn['pred_stress'], label='Predicted (TCN)', color='red', linestyle='--')
plt.title('Stress-Strain Graph: Actual vs Predicted (TCN)')
plt.xlabel('Strain (mm/mm)')
plt.ylabel('Stress (MPa)')
plt.legend()
plt.grid(True)
plt.show()

"""##Hybrid model - BiLSTM + GRU"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Bidirectional, LSTM, GRU, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import numpy as np

X = df[['Time (s)', 'Extension (mm)', 'Load (kN)', 'Sample_encoded']]
y = df[['Tensile strain (mm/mm)', 'Tensile stress (MPa)']]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=df['Sample'])

x_scaler = StandardScaler()
y_scaler = MinMaxScaler()

X_train_scaled = x_scaler.fit_transform(X_train)
X_test_scaled = x_scaler.transform(X_test)
y_train_scaled = y_scaler.fit_transform(y_train)

X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_test_reshaped = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

tuned_hybrid_model = Sequential([
    Bidirectional(LSTM(128, activation='tanh', return_sequences=True),
                  input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])),
    GRU(64, activation='tanh'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(2)
])

optimizer = Adam(learning_rate=0.001)
tuned_hybrid_model.compile(optimizer=optimizer, loss='mse')

early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

history = tuned_hybrid_model.fit(X_train_reshaped, y_train_scaled,
                                 epochs=100,
                                 batch_size=32,
                                 validation_split=0.2,
                                 callbacks=[early_stopping],
                                 verbose=1)

metrics_hybrid, y_pred_hybrid = evaluate_scaled(tuned_hybrid_model, X_test_reshaped, y_test,
                                                'BiLSTM-GRU Hybrid', split_name, scaler=y_scaler)
print(metrics_hybrid)

y_pred_scaled = tuned_hybrid_model.predict(X_test_reshaped)
y_pred_tuned = y_scaler.inverse_transform(y_pred_scaled)

r2 = r2_score(y_test, y_pred_tuned)
rmse = np.sqrt(mean_squared_error(y_test, y_pred_tuned))
mae = mean_absolute_error(y_test, y_pred_tuned)

print(f"\\nTuned Hybrid Model Results:")
print(f"R2 Score: {r2:.6f}")
print(f"RMSE: {rmse:.4f}")
print(f"MAE: {mae:.4f}")

test_df_tuned = y_test.copy()
test_df_tuned['pred_strain'] = y_pred_tuned[:, 0]
test_df_tuned['pred_stress'] = y_pred_tuned[:, 1]
test_df_tuned.sort_values('Tensile strain (mm/mm)', inplace=True)

fig, ax = plt.subplots(figsize=(15, 10))

ax.plot(test_df_tuned['Tensile strain (mm/mm)'], test_df_tuned['Tensile stress (MPa)'],
        label='Actual', color='blue', linewidth=3)
ax.plot(test_df_tuned['pred_strain'], test_df_tuned['pred_stress'],
        label='Predicted (Tuned Hybrid)', color='red', linestyle='--', linewidth=3)

ax.set_title('Stress-Strain Graph: Tuned BiLSTM-GRU Hybrid Model')
ax.set_xlabel('Strain (mm/mm)')
ax.set_ylabel('Stress (MPa)')

ax.legend()
ax.grid(True)

plt.show()

"""##Hybrid Model - BiLSTM + GRU + XGB"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Bidirectional, LSTM, GRU, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import xgboost as xgb
import numpy as np

X = df[['Time (s)', 'Extension (mm)', 'Load (kN)', 'Sample_encoded']]
y = df[['Tensile strain (mm/mm)', 'Tensile stress (MPa)']]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=df['Sample'])

x_scaler = StandardScaler()
y_scaler = MinMaxScaler()

X_train_scaled = x_scaler.fit_transform(X_train)
X_test_scaled = x_scaler.transform(X_test)
y_train_scaled = y_scaler.fit_transform(y_train)

X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_test_reshaped = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

level0_model = Sequential([
    Bidirectional(LSTM(128, activation='tanh', return_sequences=True),
                  input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])),
    GRU(64, activation='tanh'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(2)
])
optimizer = Adam(learning_rate=0.001)
level0_model.compile(optimizer=optimizer, loss='mse')
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

level0_model.fit(X_train_reshaped, y_train_scaled,
                 epochs=100,
                 batch_size=32,
                 validation_split=0.2,
                 callbacks=[early_stopping],
                 verbose=0)

train_preds_scaled = level0_model.predict(X_train_reshaped)
train_preds = y_scaler.inverse_transform(train_preds_scaled)

test_preds_scaled = level0_model.predict(X_test_reshaped)
test_preds = y_scaler.inverse_transform(test_preds_scaled)

X_train_new = np.concatenate([X_train_scaled, train_preds], axis=1)
X_test_new = np.concatenate([X_test_scaled, test_preds], axis=1)

level1_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)
level1_model.fit(X_train_new, y_train)

y_pred_final = level1_model.predict(X_test_new)

r2 = r2_score(y_test, y_pred_final)
rmse = np.sqrt(mean_squared_error(y_test, y_pred_final))
mae = mean_absolute_error(y_test, y_pred_final)

print(f"\\nFinal Stacked Hybrid (BiLSTM-GRU + XGBoost) Results:")
print(f"R2 Score: {r2:.6f}")
print(f"RMSE: {rmse:.4f}")
print(f"MAE: {mae:.4f}")

test_df_final = y_test.copy()
test_df_final['pred_strain'] = y_pred_final[:, 0]
test_df_final['pred_stress'] = y_pred_final[:, 1]
test_df_final.sort_values('Tensile strain (mm/mm)', inplace=True)

fig, ax = plt.subplots(figsize=(15, 10))

ax.plot(test_df_final['Tensile strain (mm/mm)'], test_df_final['Tensile stress (MPa)'],
        label='Actual', color='blue', linewidth=3)
ax.plot(test_df_final['pred_strain'], test_df_final['pred_stress'],
        label='Predicted (Stacked Hybrid)', color='red', linestyle='--', linewidth=3)

ax.set_title('Stress-Strain Graph: Stacked Hybrid Model (70/30 Split)')
ax.set_xlabel('Strain (mm/mm)')
ax.set_ylabel('Stress (MPa)')

ax.legend()
ax.grid(True)

plt.savefig('stacked_hybrid_70_30.tif', format='tiff', dpi=300, bbox_inches='tight')

plt.show()

"""#Top performing model on all splits"""

all_results = []
test_sizes = [0.4, 0.3, 0.2, 0.1]

X = df[['Time (s)', 'Extension (mm)', 'Load (kN)', 'Sample_encoded']]
y = df[['Tensile strain (mm/mm)', 'Tensile stress (MPa)']]

for test_size in test_sizes:
    split_name = f"train{int((1-test_size)*100)}/test{int(test_size*100)}"
    print(f"--- Processing Split: {split_name} ---")

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=df['Sample'])

    x_scaler = StandardScaler()
    y_scaler = MinMaxScaler()

    X_train_scaled = x_scaler.fit_transform(X_train)
    X_test_scaled = x_scaler.transform(X_test)
    y_train_scaled = y_scaler.fit_transform(y_train)

    X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
    X_test_reshaped = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

    level0_model = Sequential([
        Bidirectional(LSTM(128, activation='tanh', return_sequences=True),
                      input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])),
        GRU(64, activation='tanh'),
        Dropout(0.2),
        Dense(32, activation='relu'),
        Dense(2)
    ])
    optimizer = Adam(learning_rate=0.001)
    level0_model.compile(optimizer=optimizer, loss='mse')
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

    level0_model.fit(X_train_reshaped, y_train_scaled,
                     epochs=100,
                     batch_size=32,
                     validation_split=0.2,
                     callbacks=[early_stopping],
                     verbose=0)

    train_preds_scaled = level0_model.predict(X_train_reshaped)
    train_preds = y_scaler.inverse_transform(train_preds_scaled)

    test_preds_scaled = level0_model.predict(X_test_reshaped)
    test_preds = y_scaler.inverse_transform(test_preds_scaled)

    X_train_new = np.concatenate([X_train_scaled, train_preds], axis=1)
    X_test_new = np.concatenate([X_test_scaled, test_preds], axis=1)

    level1_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)
    level1_model.fit(X_train_new, y_train)

    y_pred_final = level1_model.predict(X_test_new)

    r2 = r2_score(y_test, y_pred_final)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred_final))
    mae = mean_absolute_error(y_test, y_pred_final)

    all_results.append({
        'Model': 'Stacked Hybrid', 'Split': split_name,
        'R2': r2, 'RMSE': rmse, 'MAE': mae
    })
    print(f"Results for {split_name}: R2={r2:.6f}, RMSE={rmse:.4f}, MAE={mae:.4f}")

results_df = pd.DataFrame(all_results)
print("\\n--- Final Performance Summary Across All Splits ---")
print(results_df.to_string())

"""#Annova Analysis"""

pip install statsmodels

pip install xgboost

"""##Annova analysis of best model (BiLSTM + GRU + XGB)"""

import pandas as pd
import numpy as np
import statsmodels.api as sm
from statsmodels.formula.api import ols

# All model and data preparation imports
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.multioutput import MultiOutputRegressor
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Bidirectional, LSTM, GRU, Dropout
from tensorflow.keras.optimizers import Adam
from tcn import TCN
import xgboost as xgb

le = LabelEncoder()
df['Sample_encoded'] = le.fit_transform(df['Sample'])
X = df[['Time (s)', 'Extension (mm)', 'Load (kN)', 'Sample_encoded']]
y = df[['Tensile strain (mm/mm)', 'Tensile stress (MPa)']]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=df['Sample'])

x_scaler = StandardScaler()
y_scaler = MinMaxScaler()

X_train_scaled = x_scaler.fit_transform(X_train)
X_test_scaled = x_scaler.transform(X_test)
y_train_scaled = y_scaler.fit_transform(y_train)

X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_test_reshaped = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

predictions = {}

rf_model = RandomForestRegressor(random_state=42).fit(X_train_scaled, y_train)
predictions['RandomForest'] = rf_model.predict(X_test_scaled)

dt_model = DecisionTreeRegressor(random_state=42).fit(X_train_scaled, y_train)
predictions['DecisionTree'] = dt_model.predict(X_test_scaled)

knn_model = KNeighborsRegressor().fit(X_train_scaled, y_train)
predictions['KNN'] = knn_model.predict(X_test_scaled)

svm_model = MultiOutputRegressor(SVR()).fit(X_train_scaled, y_train)
predictions['SVM'] = svm_model.predict(X_test_scaled)

ann_model = Sequential([Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]), Dense(32, activation='relu'), Dense(2)])
ann_model.compile(optimizer='adam', loss='mse')
ann_model.fit(X_train_scaled, y_train_scaled, epochs=50, batch_size=32, verbose=0)
predictions['ANN'] = y_scaler.inverse_transform(ann_model.predict(X_test_scaled))

lstm_model = Sequential([LSTM(64, activation='tanh', input_shape=(1, X_train_scaled.shape[1])), Dense(32, activation='relu'), Dense(2)])
lstm_model.compile(optimizer='adam', loss='mse')
lstm_model.fit(X_train_reshaped, y_train_scaled, epochs=50, batch_size=32, verbose=0)
predictions['LSTM'] = y_scaler.inverse_transform(lstm_model.predict(X_test_reshaped))

bilstm_model = Sequential([Bidirectional(LSTM(64, activation='tanh'), input_shape=(1, X_train_scaled.shape[1])), Dense(32, activation='relu'), Dense(2)])
bilstm_model.compile(optimizer='adam', loss='mse')
bilstm_model.fit(X_train_reshaped, y_train_scaled, epochs=50, batch_size=32, verbose=0)
predictions['BiLSTM'] = y_scaler.inverse_transform(bilstm_model.predict(X_test_reshaped))

gru_model = Sequential([GRU(64, activation='tanh', input_shape=(1, X_train_scaled.shape[1])), Dense(32, activation='relu'), Dense(2)])
gru_model.compile(optimizer='adam', loss='mse')
gru_model.fit(X_train_reshaped, y_train_scaled, epochs=50, batch_size=32, verbose=0)
predictions['GRU'] = y_scaler.inverse_transform(gru_model.predict(X_test_reshaped))

tcn_model = Sequential([TCN(64, activation='relu', input_shape=(1, X_train_scaled.shape[1])), Dense(32, activation='relu'), Dense(2)])
tcn_model.compile(optimizer='adam', loss='mse')
tcn_model.fit(X_train_reshaped, y_train_scaled, epochs=50, batch_size=32, verbose=0)
predictions['TCN'] = y_scaler.inverse_transform(tcn_model.predict(X_test_reshaped))

tuned_hybrid_model = Sequential([Bidirectional(LSTM(128, activation='tanh', return_sequences=True), input_shape=(1, X_train_scaled.shape[1])), GRU(64, activation='tanh'), Dropout(0.2), Dense(32, activation='relu'), Dense(2)])
tuned_hybrid_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')
tuned_hybrid_model.fit(X_train_reshaped, y_train_scaled, epochs=50, batch_size=32, validation_split=0.2, verbose=0)
predictions['Tuned_Hybrid'] = y_scaler.inverse_transform(tuned_hybrid_model.predict(X_test_reshaped))

level0_preds_train = y_scaler.inverse_transform(tuned_hybrid_model.predict(X_train_reshaped))
level0_preds_test = predictions['Tuned_Hybrid']
X_train_new = np.concatenate([X_train_scaled, level0_preds_train], axis=1)
X_test_new = np.concatenate([X_test_scaled, level0_preds_test], axis=1)
level1_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42).fit(X_train_new, y_train)
predictions['Stacked_Hybrid'] = level1_model.predict(X_test_new)

summary_data = []

from sklearn.metrics import r2_score

error_metrics = {
    'MAE': lambda y_true, y_pred: np.abs(y_true - y_pred),
    'MSE': lambda y_true, y_pred: (y_true - y_pred) ** 2,
    'R2': lambda y_true, y_pred: r2_score(y_true, y_pred)
}

targets = {'Tensile Strain': 0, 'Tensile Stress': 1}

for metric_name, error_func in error_metrics.items():
    for target_name, target_index in targets.items():
        error_data = []

        if metric_name != 'R2':
            for model_name, y_pred in predictions.items():
                errors = error_func(y_test.iloc[:, target_index], y_pred[:, target_index])
                for error in errors:
                    error_data.append({'Model': model_name, 'Error': error})

            error_df = pd.DataFrame(error_data)
            model_lm = ols('Error ~ C(Model)', data=error_df).fit()
            anova_table = sm.stats.anova_lm(model_lm, typ=2)

            for source in ['C(Model)', 'Residual', 'Total']:
                if source == 'Total':
                    df_val = anova_table['df'].sum()
                    ss_val = anova_table['sum_sq'].sum()
                    ms_val, f_val, p_val = '', '', ''
                else:
                    row = anova_table.loc[source]
                    df_val = int(row['df'])
                    ss_val = f"{row['sum_sq']:.4f}"
                    ms_val = f"{(row['sum_sq'] / row['df']):.4f}"
                    f_val = f"{row['F']:.2f}" if not pd.isna(row['F']) else ''
                    p_val = "P < 0.05" if row['PR(>F)'] < 0.05 else ''

                summary_data.append({
                    'Error Metrics': metric_name,
                    'Target': target_name,
                    'Source': 'Model' if source == 'C(Model)' else source,
                    'Degree of freedom': df_val,
                    'Adjusted sum of squares': ss_val,
                    'Adjusted mean squares': ms_val,
                    'F-value': f_val,
                    'P-value': p_val
                })

        else:
            r2_scores = []
            for model_name, y_pred in predictions.items():
                r2_val = error_func(y_test.iloc[:, target_index], y_pred[:, target_index])
                r2_scores.append({'Model': model_name, 'R2': r2_val})

            r2_df = pd.DataFrame(r2_scores)

            model_lm = ols('R2 ~ C(Model)', data=r2_df).fit()
            anova_table = sm.stats.anova_lm(model_lm, typ=2)

            for source in ['C(Model)', 'Residual', 'Total']:
                if source == 'Total':
                    df_val = anova_table['df'].sum()
                    ss_val = anova_table['sum_sq'].sum()
                    ms_val, f_val, p_val = '', '', ''
                else:
                    row = anova_table.loc[source]
                    df_val = int(row['df'])
                    ss_val = f"{row['sum_sq']:.4f}"
                    ms_val = f"{(row['sum_sq'] / row['df']):.4f}"
                    f_val = f"{row['F']:.2f}" if not pd.isna(row['F']) else ''
                    p_val = "P < 0.05" if row['PR(>F)'] < 0.05 else ''

                summary_data.append({
                    'Error Metrics': 'R2',
                    'Target': target_name,
                    'Source': 'Model' if source == 'C(Model)' else source,
                    'Degree of freedom': df_val,
                    'Adjusted sum of squares': ss_val,
                    'Adjusted mean squares': ms_val,
                    'F-value': f_val,
                    'P-value': p_val
                })

final_summary_table = pd.DataFrame(summary_data).set_index(['Error Metrics', 'Target', 'Source'])

print("\n\n--- Final ANOVA Summary Table ---")
print(final_summary_table.to_string())

"""##Annova test results of dataset"""

import pandas as pd
import statsmodels.api as sm
from statsmodels.formula.api import ols

df = pd.read_csv('BTP Dataset - Sheet1.csv', header=0, skiprows=[1])
df.columns = ['Sample', 'Time', 'Extension', 'Load', 'Strain', 'Stress']

def perform_feature_anova(dataframe, response_variable):
    formula = f"""{response_variable} ~ Time + Extension + Load
                    + I(Time**2) + I(Extension**2) + I(Load**2)
                    + Time:Extension + Time:Load + Extension:Load"""
    model = ols(formula, data=dataframe).fit()
    anova_table = sm.stats.anova_lm(model, typ=2)

    anova_table = anova_table.rename(columns={
        "df": "Degree of freedom",
        "sum_sq": "Adjusted sum of squares",
        "mean_sq": "Adjusted mean squares",
        "F": "F-value",
        "PR(>F)": "P-value"
    })

    remarks = []
    for p in anova_table["P-value"]:
        if pd.isna(p):
            remarks.append('')
        elif p < 0.05:
            remarks.append('Significant')
        else:
            remarks.append('Not Significant')
    anova_table["Remarks"] = remarks

    return anova_table

print("--- ANOVA for Stress ---")
anova_stress = perform_feature_anova(df, "Stress")
print(anova_stress.to_string())

print("\n\n--- ANOVA for Strain ---")
anova_strain = perform_feature_anova(df, "Strain")
print(anova_strain.to_string())

predictions = {}
print("--- Gathering predictions from pre-trained models... ---")

# --- Scikit-learn Models ---
predictions['RandomForest'] = rf_model.predict(X_test_scaled_main)
predictions['DecisionTree'] = dt_model.predict(X_test_scaled_main)
predictions['KNN'] = knn_model.predict(X_test_scaled_main)
predictions['SVM'] = svm_model.predict(X_test_scaled_main)

# --- Keras/TensorFlow Models ---
predictions['ANN'] = y_scaler_main.inverse_transform(ann_model.predict(X_test_scaled_main))
predictions['LSTM'] = y_scaler_main.inverse_transform(lstm_model.predict(X_test_reshaped_main))
predictions['BiLSTM'] = y_scaler_main.inverse_transform(bilstm_model.predict(X_test_reshaped_main))
predictions['GRU'] = y_scaler_main.inverse_transform(gru_model.predict(X_test_reshaped_main))
predictions['TCN'] = y_scaler_main.inverse_transform(tcn_model.predict(X_test_reshaped_main))
predictions['Tuned_Hybrid'] = y_scaler_main.inverse_transform(tuned_hybrid_model.predict(X_test_reshaped_main))

# --- Stacked Hybrid Model ---
level0_preds_test = predictions['Tuned_Hybrid']
X_test_new = np.concatenate([X_test_scaled_main, level0_preds_test], axis=1)
predictions['Stacked_Hybrid'] = level1_model.predict(X_test_new)

print("--- All predictions gathered successfully. ---")

def run_anova_and_print_table(predictions_dict, y_test_data, target_index, target_name):
    error_data = []
    for model_name, y_pred in predictions_dict.items():
        errors = np.abs(y_pred[:, target_index] - y_test_data.iloc[:, target_index])
        for error in errors:
            error_data.append({'Model': model_name, 'Error': error})

    error_df = pd.DataFrame(error_data)

    model_lm = ols('Error ~ C(Model)', data=error_df).fit()
    anova_table = sm.stats.anova_lm(model_lm, typ=2)

    # Format table
    anova_table.index.name = "Source"
    anova_table.rename(columns={'df': 'DF', 'sum_sq': 'SS', 'mean_sq': 'MS', 'F': 'F', 'PR(>F)': 'P'}, inplace=True)

    print(f"\n--- ANOVA Table for {target_name} Errors ---")
    print(anova_table.to_string())

# Run ANOVA for Stress (using the consistent y_test_main)
run_anova_and_print_table(predictions, y_test_main, 1, "Tensile Stress")

# Run ANOVA for Strain (using the consistent y_test_main)
run_anova_and_print_table(predictions, y_test_main, 0, "Tensile Strain")

import pandas as pd
import numpy as np
import statsmodels.api as sm
from statsmodels.formula.api import ols

def format_and_print_anova(predictions, y_test_data, target_index, target_name):
    """
    Runs ANOVA and formats the results into the requested table style.
    """
    # Create a dataframe of errors for the ANOVA model
    error_data = []
    for model_name, y_pred in predictions.items():
        errors = np.abs(y_pred[:, target_index] - y_test_data.iloc[:, target_index])
        for error in errors:
            error_data.append({'Model': model_name, 'Error': error})
    error_df = pd.DataFrame(error_data)

    # Perform the ANOVA
    model_lm = ols('Error ~ C(Model)', data=error_df).fit()
    anova_table = sm.stats.anova_lm(model_lm, typ=2)

    # --- Table Formatting (Corrected) ---

    # Extract values from the anova_table
    ss_model = anova_table['sum_sq']['C(Model)']
    df_model = anova_table['df']['C(Model)']
    ss_error = anova_table['sum_sq']['Residual']
    df_error = anova_table['df']['Residual']

    # Manually calculate Mean Square (MS = SS / DF)
    ms_model = ss_model / df_model
    ms_error = ss_error / df_error

    # Calculate Totals
    ss_total = ss_model + ss_error
    df_total = df_model + df_error

    f_value = anova_table['F']['C(Model)']
    p_value = anova_table['PR(>F)']['C(Model)']

    # Create the final formatted DataFrame
    formatted_data = {
        'Source': ['Model', 'Error', 'Total'],
        'DF': [int(df_model), int(df_error), int(df_total)],
        'SS': [f'{ss_model:.2e}', f'{ss_error:.2e}', f'{ss_total:.2e}'],
        'MS': [f'{ms_model:.2e}', f'{ms_error:.2f}', ''],
        'F': [f'{f_value:.2f}', '', ''],
        'P': [f'{p_value:.1f}', '', '']
    }

    final_table = pd.DataFrame(formatted_data).set_index('Source')

    print(f"--- ANOVA Table for {target_name} ---")
    print(final_table.to_string())

# --- Run Analysis for Stress and Strain ---
# This assumes the 'predictions' and 'y_test_main' variables
# are available from the previous step.

# ANOVA for Tensile Stress (column index 1)
format_and_print_anova(predictions, y_test_main, 1, "Tensile Stress")

# ANOVA for Tensile Strain (column index 0)
format_and_print_anova(predictions, y_test_main, 0, "Tensile Strain")

import pandas as pd
import numpy as np
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# This assumes the 'predictions' dictionary and 'y_test_main' DataFrame
# are available from the previous step.

model_performance = []

for model_name, y_pred in predictions.items():
    r2 = r2_score(y_test_main, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test_main, y_pred))
    mae = mean_absolute_error(y_test_main, y_pred)

    model_performance.append({
        'Model': model_name,
        'R2 Score': r2,
        'RMSE': rmse,
        'MAE': mae
    })

# Create a DataFrame and sort by the most important metrics
performance_df = pd.DataFrame(model_performance)
performance_df_sorted = performance_df.sort_values(by=['R2 Score', 'RMSE'], ascending=[False, True]).reset_index(drop=True)

print("--- Final Model Performance Ranking ---")
print(performance_df_sorted.to_string())

import pandas as pd
import numpy as np
import statsmodels.api as sm
from statsmodels.formula.api import ols

def generate_final_anova_summary(predictions, y_test_data):
    """
    Runs ANOVA for both Stress and Strain errors and formats the results
    into a single, final summary table.
    """
    summary_data = []

    for target_index, target_name in enumerate(["Tensile Strain", "Tensile Stress"]):
        # Create a dataframe of errors for the current target
        error_data = []
        for model_name, y_pred in predictions.items():
            errors = np.abs(y_pred[:, target_index] - y_test_data.iloc[:, target_index])
            for error in errors:
                error_data.append({'Model': model_name, 'Error': error})
        error_df = pd.DataFrame(error_data)

        # Perform the ANOVA
        model_lm = ols('Error ~ C(Model)', data=error_df).fit()
        anova_table = sm.stats.anova_lm(model_lm, typ=2)

        # Extract the key results from the 'Model' row of the ANOVA
        model_row = anova_table.loc['C(Model)']
        summary_data.append({
            'Error Metrics': f'{target_name} Error',
            'DF': int(model_row['df']),
            'SS': f"{model_row['sum_sq']:.2e}",
            'MS': f"{(model_row['sum_sq'] / model_row['df']):.2e}",
            'F': f"{model_row['F']:.2f}",
            'P': f"{model_row['PR(>F)']:.1f}"
        })

    # Create and display the final DataFrame
    final_summary_table = pd.DataFrame(summary_data).set_index('Error Metrics')

    print("--- Final ANOVA Summary ---")
    print(final_summary_table.to_string())

# --- Run the final analysis ---
# This assumes the 'predictions' dictionary and 'y_test_main' DataFrame
# are available from your previous steps.
generate_final_anova_summary(predictions, y_test_main)

"""#SHAP plot analysis"""

pip install shap

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import xgboost as xgb
import shap
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Bidirectional, LSTM, GRU, Dropout
from tensorflow.keras.optimizers import Adam

le = LabelEncoder()
df['Sample_encoded'] = le.fit_transform(df['Sample'])
X = df[['Time (s)', 'Extension (mm)', 'Load (kN)', 'Sample_encoded']]
y = df[['Strain (mm/mm)', 'Stress (MPa)']]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=df['Sample'])

x_scaler = StandardScaler()
y_scaler = MinMaxScaler()
X_train_scaled = x_scaler.fit_transform(X_train)
X_test_scaled = x_scaler.transform(X_test)
y_train_scaled = y_scaler.fit_transform(y_train)
X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_test_reshaped = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

level0_model = Sequential([
    Bidirectional(LSTM(128, activation='tanh', return_sequences=True), input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])),
    GRU(64, activation='tanh'), Dropout(0.2), Dense(32, activation='relu'), Dense(2)
])
level0_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')
print("--- Training Level-0 BiLSTM-GRU Model... ---")
level0_model.fit(X_train_reshaped, y_train_scaled, epochs=50, batch_size=32, validation_split=0.2, verbose=0)

print("--- Generating predictions from Level-0 model... ---")
train_preds_scaled = level0_model.predict(X_train_reshaped)
train_preds = y_scaler.inverse_transform(train_preds_scaled)
test_preds_scaled = level0_model.predict(X_test_reshaped)
test_preds = y_scaler.inverse_transform(test_preds_scaled)

X_train_new = np.concatenate([X_train_scaled, train_preds], axis=1)
X_test_new = np.concatenate([X_test_scaled, test_preds], axis=1)
feature_names = list(X.columns) + ['Strain from Hybrid Model', 'Stress from Hybrid Model']
feature_names = ['Time (s)', 'Extension (mm)', 'Load (kN)', 'Samples'] + ['Strain from Hybrid Model', 'Stress from Hybrid Model']

X_test_new_df = pd.DataFrame(X_test_new, columns=feature_names)

print("--- Training two separate Level-1 XGBoost Models... ---")
xgb_stress_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)
xgb_stress_model.fit(X_train_new, y_train.iloc[:, 1])

xgb_strain_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)
xgb_strain_model.fit(X_train_new, y_train.iloc[:, 0])

explainer_stress = shap.TreeExplainer(xgb_stress_model)
shap_values_stress = explainer_stress.shap_values(X_test_new_df)

explainer_strain = shap.TreeExplainer(xgb_strain_model)
shap_values_strain = explainer_strain.shap_values(X_test_new_df)

shap.summary_plot(shap_values_stress, X_test_new_df, show=False)
fig = plt.gcf()
fig.set_size_inches(25, 10)
ax = plt.gca()

ax.set_xlabel("SHAP value (Predicted Stress)", fontsize=30, fontweight='bold')
ax.set_ylabel("Feature", fontsize=30, fontweight='bold')
ax.tick_params(axis='both', which='major', labelsize=30)

cb_ax = fig.axes[1]
cb_ax.tick_params(labelsize=24)
cb_ax.set_ylabel(cb_ax.get_ylabel(), fontsize=24)

for label in (ax.get_xticklabels() + ax.get_yticklabels()):
    label.set_fontweight('bold')

plt.tight_layout()
plt.savefig('final_shap_stress_large_font_colorbar.tif', format='tiff', dpi=300, bbox_inches='tight')
plt.show()


# --- SHAP Plot for Tensile Strain ---
print("\nSHAP Summary Plot for Tensile Strain")
shap.summary_plot(shap_values_strain, X_test_new_df, show=False)
fig = plt.gcf()
fig.set_size_inches(25, 10)
ax = plt.gca()

ax.set_xlabel("SHAP value (Predicted Strain)", fontsize=30, fontweight='bold')
ax.set_ylabel("Feature", fontsize=30, fontweight='bold')
ax.tick_params(axis='both', which='major', labelsize=30)

cb_ax = fig.axes[1]
cb_ax.tick_params(labelsize=24)
cb_ax.set_ylabel(cb_ax.get_ylabel(), fontsize=24)

for label in (ax.get_xticklabels() + ax.get_yticklabels()):
    label.set_fontweight('bold')

plt.tight_layout()
plt.savefig('final_shap_strain_large_font_colorbar.tif', format='tiff', dpi=300, bbox_inches='tight')
plt.show()

plot_style = {'font.family': 'serif', 'font.weight': 'bold'}
plt.rcParams.update(plot_style)

def plot_shap_scatter(ax, feature_name, shap_values, feature_values, ylabel):
    colors = ["#ff0000" if val > 0 else "#0000ff" for val in shap_values] # Red for positive, Blue for negative
    ax.scatter(feature_values, shap_values, c=colors, alpha=0.7, s=20, edgecolors='k', linewidth=0.5)
    ax.axhline(0, color='black', linestyle='--', linewidth=1.5)
    ax.set_xlabel(feature_name, fontsize=44, fontweight='bold')
    ax.set_ylabel(f"SHAP value for {ylabel}", fontsize=44, fontweight='bold')
    ax.tick_params(axis='both', which='major', labelsize=40)
    for label in (ax.get_xticklabels() + ax.get_yticklabels()):
        label.set_fontweight('bold')

fig, axs = plt.subplots(2, 2, figsize=(30, 25))

plot_shap_scatter(axs[0,0], "Load (kN)",
                  shap_values_stress[:, X_test_new_df.columns.get_loc("Load (kN)")],
                  X_test_new_df["Load (kN)"], "Stress")

plot_shap_scatter(axs[0,1], "Predicted Stress from Hybrid Model",
                  shap_values_stress[:, X_test_new_df.columns.get_loc("Stress from Hybrid Model")],
                  X_test_new_df["Stress from Hybrid Model"], "Stress")

plot_shap_scatter(axs[1,0], "Extension (mm)",
                  shap_values_strain[:, X_test_new_df.columns.get_loc("Extension (mm)")],
                  X_test_new_df["Extension (mm)"], "Strain")

rounded_strain_preds = X_test_new_df["Strain from Hybrid Model"].round(2)

plot_shap_scatter(axs[1,1], "Predicted Strain from Hybrid Model",
                  shap_values_strain[:, X_test_new_df.columns.get_loc("Strain from Hybrid Model")],
                  rounded_strain_preds, "Strain")

plt.tight_layout(rect=[0, 0, 1, 0.97])
plt.savefig('shap_dependence_grid.tif', format='tiff', dpi=300, bbox_inches='tight')
plt.show()

import pandas as pd
import numpy as np

mean_abs_shap_stress = np.abs(shap_values_stress).mean(axis=0)
stress_importance_df = pd.DataFrame({
    'Feature': X_test_new_df.columns,
    'Mean_Absolute_SHAP_Value': mean_abs_shap_stress
}).sort_values(by='Mean_Absolute_SHAP_Value', ascending=False).reset_index(drop=True)

mean_abs_shap_strain = np.abs(shap_values_strain).mean(axis=0)
strain_importance_df = pd.DataFrame({
    'Feature': X_test_new_df.columns,
    'Mean_Absolute_SHAP_Value': mean_abs_shap_strain
}).sort_values(by='Mean_Absolute_SHAP_Value', ascending=False).reset_index(drop=True)

print("--- Feature Importance for Tensile Stress ---")
print(stress_importance_df.to_string())

print("\n--- Feature Importance for Tensile Strain ---")
print(strain_importance_df.to_string())

"""#Linear Fitting"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from sklearn.metrics import r2_score, mean_absolute_error

from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.multioutput import MultiOutputRegressor
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Bidirectional, LSTM, GRU, Dropout
from tensorflow.keras.optimizers import Adam
from tcn import TCN
import xgboost as xgb

print("--- Preparing a consistent 70/30 data split... ---")
le = LabelEncoder()
df['Sample_encoded'] = le.fit_transform(df['Sample'])
X = df[['Time (s)', 'Extension (mm)', 'Load (kN)', 'Sample_encoded']]
y = df[['Strain (mm/mm)', 'Stress (MPa)']]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=df['Sample'])

x_scaler = StandardScaler()
y_scaler = MinMaxScaler()

X_train_scaled = x_scaler.fit_transform(X_train)
X_test_scaled = x_scaler.transform(X_test)
y_train_scaled = y_scaler.fit_transform(y_train)

X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_test_reshaped = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

predictions = {}

rf_model = RandomForestRegressor(random_state=42).fit(X_train_scaled, y_train)
predictions['RandomForest'] = rf_model.predict(X_test_scaled)

dt_model = DecisionTreeRegressor(random_state=42).fit(X_train_scaled, y_train)
predictions['DecisionTree'] = dt_model.predict(X_test_scaled)

knn_model = KNeighborsRegressor().fit(X_train_scaled, y_train)
predictions['KNN'] = knn_model.predict(X_test_scaled)

svm_model = MultiOutputRegressor(SVR()).fit(X_train_scaled, y_train)
predictions['SVM'] = svm_model.predict(X_test_scaled)

ann_model = Sequential([Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]), Dense(32, activation='relu'), Dense(2)])
ann_model.compile(optimizer='adam', loss='mse')
ann_model.fit(X_train_scaled, y_train_scaled, epochs=50, batch_size=32, verbose=0)
predictions['ANN'] = y_scaler.inverse_transform(ann_model.predict(X_test_scaled))

lstm_model = Sequential([LSTM(64, activation='tanh', input_shape=(1, X_train_scaled.shape[1])), Dense(32, activation='relu'), Dense(2)])
lstm_model.compile(optimizer='adam', loss='mse')
lstm_model.fit(X_train_reshaped, y_train_scaled, epochs=50, batch_size=32, verbose=0)
predictions['LSTM'] = y_scaler.inverse_transform(lstm_model.predict(X_test_reshaped))

bilstm_model = Sequential([Bidirectional(LSTM(64, activation='tanh'), input_shape=(1, X_train_scaled.shape[1])), Dense(32, activation='relu'), Dense(2)])
bilstm_model.compile(optimizer='adam', loss='mse')
bilstm_model.fit(X_train_reshaped, y_train_scaled, epochs=50, batch_size=32, verbose=0)
predictions['BiLSTM'] = y_scaler.inverse_transform(bilstm_model.predict(X_test_reshaped))

gru_model = Sequential([GRU(64, activation='tanh', input_shape=(1, X_train_scaled.shape[1])), Dense(32, activation='relu'), Dense(2)])
gru_model.compile(optimizer='adam', loss='mse')
gru_model.fit(X_train_reshaped, y_train_scaled, epochs=50, batch_size=32, verbose=0)
predictions['GRU'] = y_scaler.inverse_transform(gru_model.predict(X_test_reshaped))

tcn_model = Sequential([TCN(64, activation='relu', input_shape=(1, X_train_scaled.shape[1])), Dense(32, activation='relu'), Dense(2)])
tcn_model.compile(optimizer='adam', loss='mse')
tcn_model.fit(X_train_reshaped, y_train_scaled, epochs=50, batch_size=32, verbose=0)
predictions['TCN'] = y_scaler.inverse_transform(tcn_model.predict(X_test_reshaped))

tuned_hybrid_model = Sequential([Bidirectional(LSTM(128, activation='tanh', return_sequences=True), input_shape=(1, X_train_scaled.shape[1])), GRU(64, activation='tanh'), Dropout(0.2), Dense(32, activation='relu'), Dense(2)])
tuned_hybrid_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')
tuned_hybrid_model.fit(X_train_reshaped, y_train_scaled, epochs=50, batch_size=32, validation_split=0.2, verbose=0)
predictions['Tuned_Hybrid'] = y_scaler.inverse_transform(tuned_hybrid_model.predict(X_test_reshaped))

level0_preds_train = y_scaler.inverse_transform(tuned_hybrid_model.predict(X_train_reshaped))
level0_preds_test = predictions['Tuned_Hybrid']
X_train_new = np.concatenate([X_train_scaled, level0_preds_train], axis=1)
X_test_new = np.concatenate([X_test_scaled, level0_preds_test], axis=1)
level1_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42).fit(X_train_new, y_train)
predictions['Stacked_Hybrid'] = level1_model.predict(X_test_new)

plot_style = {
    'font.family': 'serif',
    'axes.linewidth': 3,
    'xtick.major.width': 2,
    'xtick.major.size': 8,
    'ytick.major.width': 2,
    'ytick.major.size': 8,
    'font.weight': 'bold'
}
plt.rcParams.update(plot_style)

def plot_and_save_in_groups(predictions_dict, y_true_df, target_index, target_name_with_units):
    model_names = list(predictions_dict.keys())

    def create_plot(models_to_plot, file_suffix):
        num_models = len(models_to_plot)
        fig, axes = plt.subplots(nrows=1, ncols=num_models, figsize=(15 * num_models, 15))

        target_name = target_name_with_units.split(' ')[0]

        if num_models == 1:
            axes = [axes]

        for i, model_name in enumerate(models_to_plot):
            ax = axes[i]
            y_pred = predictions_dict[model_name]
            y_true = y_true_df.iloc[:, target_index]
            y_pred_target = y_pred[:, target_index]

            r2 = r2_score(y_true, y_pred_target)
            mae = mean_absolute_error(y_true, y_pred_target)

            ax.scatter(y_true, y_pred_target, alpha=0.5, edgecolors='k', c='#1f77b4')

            min_val = min(y_true.min(), y_pred_target.min())
            max_val = max(y_true.max(), y_pred_target.max())
            ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=3)

            ax.set_title(model_name, fontsize=44, fontweight='bold')
            ax.set_xlabel(f"Actual {target_name_with_units}", fontsize=44, fontweight='bold')
            ax.set_ylabel(f"Predicted {target_name_with_units}", fontsize=44, fontweight='bold')
            ax.grid(True, linestyle='--', alpha=0.6)
            ax.tick_params(axis='both', which='major', labelsize=40)

            textstr = f'$\\bf R^2$ = {r2:.4f}\nMAE = {mae:.4f}'
            props = dict(boxstyle='round', facecolor='white', alpha=0.8)
            ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=35, verticalalignment='top', bbox=props)

        plt.tight_layout(rect=[0, 0, 1, 0.97])
        plt.savefig(f'actual_vs_predicted_{target_name}_{file_suffix}.tif', format='tiff', dpi=300, bbox_inches='tight')
        plt.show()

    create_plot(model_names[0:4], "part1")
    create_plot(model_names[4:8], "part2")
    create_plot(model_names[8:11], "part3")

plot_and_save_in_groups(predictions, y_test, 1, "Stress (MPa)")

plot_and_save_in_groups(predictions, y_test, 0, "Strain (mm/mm)")



"""#Stress-Strain Curves"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import xgboost as xgb
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from sklearn.multioutput import MultiOutputRegressor
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Bidirectional, LSTM, GRU, Dropout
from tensorflow.keras.optimizers import Adam

df = pd.read_csv('BTP Dataset - Sheet1.csv', header=0, skiprows=[1])
df.columns = ['Sample', 'Time (s)', 'Extension (mm)', 'Load (kN)', 'Strain (mm/mm)', 'Stress (MPa)']

df['Sample_encoded'] = le.fit_transform(df['Sample'])
print("Data loaded successfully.")

train_df = df.copy()
feature_cols = ['Time (s)', 'Extension (mm)', 'Load (kN)', 'Sample_encoded']
target_cols = ['Strain (mm/mm)', 'Stress (MPa)']

X_train = train_df[feature_cols]
y_train = train_df[target_cols]

x_scaler = StandardScaler()
y_scaler = MinMaxScaler()

X_train_scaled = x_scaler.fit_transform(X_train)
y_train_scaled = y_scaler.fit_transform(y_train)

X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))

level0_model = Sequential([
    Bidirectional(LSTM(128, activation='tanh', return_sequences=True), input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])),
    GRU(64, activation='tanh'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(2)
])
level0_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')
level0_model.fit(X_train_reshaped, y_train_scaled, epochs=50, batch_size=32, verbose=1)

train_preds_scaled = level0_model.predict(X_train_reshaped)
train_preds = y_scaler.inverse_transform(train_preds_scaled)
X_train_new = np.concatenate([X_train_scaled, train_preds], axis=1)

xgb_level1 = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)
champion_model = MultiOutputRegressor(estimator=xgb_level1)
champion_model.fit(X_train_new, y_train)

max_strain_limit = 0.20
max_stress_limit = df['Stress (MPa)'].max() * 1.05


def plot_stacked_model_curve(start_row, end_row, plot_name,
                             level0_model, champion_model,
                             data_df, label_encoder, x_scaler, y_scaler):

    slice_df = data_df.loc[start_row:end_row].copy()
    if slice_df.empty:
        print("Error: The specified row range is empty or invalid.")
        return

    feature_cols = ['Time (s)', 'Extension (mm)', 'Load (kN)', 'Sample']
    target_cols = ['Strain (mm/mm)', 'Stress (MPa)']

    X_slice = slice_df[feature_cols].copy()
    y_slice_actual = slice_df[target_cols]

    X_slice['Sample_encoded'] = label_encoder.transform(X_slice['Sample'])
    X_slice_numeric = X_slice.drop(columns=['Sample'])
    X_slice_scaled = x_scaler.transform(X_slice_numeric)

    X_slice_reshaped = np.reshape(X_slice_scaled, (X_slice_scaled.shape[0], 1, X_slice_scaled.shape[1]))
    level0_preds_scaled = level0_model.predict(X_slice_reshaped, verbose=0)
    level0_preds = y_scaler.inverse_transform(level0_preds_scaled)

    X_slice_new_features = np.concatenate([X_slice_scaled, level0_preds], axis=1)
    y_slice_pred = champion_model.predict(X_slice_new_features)

    if y_slice_pred.ndim != 2 or y_slice_pred.shape[1] != 2:
        print(f"--> MODEL PREDICTION ERROR <---")
        print(f"The model's output shape is {y_slice_pred.shape}, but it should be (n_samples, 2).")
        print("Please ensure your champion_model was trained with 'MultiOutputRegressor'.")
        return

    max_stress_idx_actual = y_slice_actual.iloc[:, 1].idxmax()
    y_actual_increasing = y_slice_actual.loc[:max_stress_idx_actual]
    max_stress_idx_pred = np.argmax(y_slice_pred[:, 1])
    y_pred_increasing = y_slice_pred[:max_stress_idx_pred + 1, :]

    plt.figure(figsize=(12, 8))
    plt.plot(y_actual_increasing.iloc[:, 0], y_actual_increasing.iloc[:, 1],
             label=f'Actual Data ({plot_name})', color='red', linewidth=2)
    plt.plot(y_pred_increasing[:, 0], y_pred_increasing[:, 1],
             label=f'Stacked Model Prediction ({plot_name})', color='blue', linestyle='--', linewidth=2.5)

    plt.xlim(0, max_strain_limit)
    plt.ylim(0, max_stress_limit)

    plt.title(f'Stress-Strain Curve for {plot_name}', fontsize=36)

    plt.xlabel('Strain (mm/mm)', fontsize=30)
    plt.ylabel('Stress (MPa)', fontsize=30)
    plt.tick_params(axis='both', which='major', labelsize=30)
    plt.legend(loc='upper left', fontsize=12)

    plt.grid(True)
    plt.savefig(f'stress_strain_curve_{plot_name}.tif', format='tiff', dpi=300, bbox_inches='tight')
    plt.show()

plot_stacked_model_curve(19683, 21187, plot_name="Transverse",
                         level0_model=level0_model,
                         champion_model=champion_model,
                         data_df=df,
                         label_encoder=le,
                         x_scaler=x_scaler,
                         y_scaler=y_scaler)

plot_stacked_model_curve(18412, 19682, plot_name="Out In",
                         level0_model=level0_model,
                         champion_model=champion_model,
                         data_df=df,
                         label_encoder=le,
                         x_scaler=x_scaler,
                         y_scaler=y_scaler)

plot_stacked_model_curve(14225, 15631, plot_name="Longitudinal",
                         level0_model=level0_model,
                         champion_model=champion_model,
                         data_df=df,
                         label_encoder=le,
                         x_scaler=x_scaler,
                         y_scaler=y_scaler)

plot_stacked_model_curve(9907, 11125, plot_name="Inclined",
                         level0_model=level0_model,
                         champion_model=champion_model,
                         data_df=df,
                         label_encoder=le,
                         x_scaler=x_scaler,
                         y_scaler=y_scaler)

plot_stacked_model_curve(6715, 8061, plot_name="In Out",
                         level0_model=level0_model,
                         champion_model=champion_model,
                         data_df=df,
                         label_encoder=le,
                         x_scaler=x_scaler,
                         y_scaler=y_scaler)

plot_stacked_model_curve(2417, 3929, plot_name="Base",
                         level0_model=level0_model,
                         champion_model=champion_model,
                         data_df=df,
                         label_encoder=le,
                         x_scaler=x_scaler,
                         y_scaler=y_scaler)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Bidirectional, LSTM, GRU, Dropout
from tensorflow.keras.optimizers import Adam

class StrainMeanAbsoluteError(tf.keras.metrics.Metric):
    def __init__(self, name='mae_strain', **kwargs):
        super(StrainMeanAbsoluteError, self).__init__(name=name, **kwargs)
        self.mae = self.add_weight(name='mae', initializer='zeros')
        self.count = self.add_weight(name='count', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        error = tf.abs(y_true[:, 0] - y_pred[:, 0])
        self.mae.assign_add(tf.reduce_sum(error))
        self.count.assign_add(tf.cast(tf.size(error), tf.float32))

    def result(self):
        return self.mae / self.count

    def reset_state(self):
        self.mae.assign(0.)
        self.count.assign(0.)

class StressMeanAbsoluteError(tf.keras.metrics.Metric):
    def __init__(self, name='mae_stress', **kwargs):
        super(StressMeanAbsoluteError, self).__init__(name=name, **kwargs)
        self.mae = self.add_weight(name='mae', initializer='zeros')
        self.count = self.add_weight(name='count', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        error = tf.abs(y_true[:, 1] - y_pred[:, 1])
        self.mae.assign_add(tf.reduce_sum(error))
        self.count.assign_add(tf.cast(tf.size(error), tf.float32))

    def result(self):
        return self.mae / self.count

    def reset_state(self):
        self.mae.assign(0.)
        self.count.assign(0.)

le = LabelEncoder()
df['Sample_encoded'] = le.fit_transform(df['Sample'])
X = df[['Time (s)', 'Extension (mm)', 'Load (kN)', 'Sample_encoded']]
y = df[['Strain (mm/mm)', 'Stress (MPa)']]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=df['Sample'])

x_scaler = StandardScaler()
y_scaler = MinMaxScaler()
X_train_scaled = x_scaler.fit_transform(X_train)
y_train_scaled = y_scaler.fit_transform(y_train)
X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))

level0_model = Sequential([
    Bidirectional(LSTM(128, activation='tanh', return_sequences=True), input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])),
    GRU(64, activation='tanh'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(2)
])

level0_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=[StrainMeanAbsoluteError(), StressMeanAbsoluteError()])

history = level0_model.fit(X_train_reshaped, y_train_scaled,
                           epochs=100,
                           batch_size=32,
                           validation_split=0.2,
                           verbose=1)

strain_range = 1 / y_scaler.scale_[0]
stress_range = 1 / y_scaler.scale_[1]

mae_strain_unscaled = np.array(history.history['mae_strain']) * strain_range
val_mae_strain_unscaled = np.array(history.history['val_mae_strain']) * strain_range
mae_stress_unscaled = np.array(history.history['mae_stress']) * stress_range
val_mae_stress_unscaled = np.array(history.history['val_mae_stress']) * stress_range

plot_style = {
    'font.family': 'serif',
    'font.weight': 'bold'
}
plt.rcParams.update(plot_style)

fig, ax = plt.subplots(figsize=(20, 15))

ax.plot(history.history['mae'], label='Training MAE', color='#1f77b4', linewidth=4)

ax.set_xlabel('Epochs', fontsize=44, fontweight='bold')
ax.set_ylabel('Mean Absolute Error (MAE)', fontsize=44, fontweight='bold')
ax.tick_params(axis='both', which='major', labelsize=40)

legend = ax.legend(fontsize=32)
plt.setp(legend.get_title(), fontsize=34, fontweight='bold')

for label in (ax.get_xticklabels() + ax.get_yticklabels()):
    label.set_fontweight('bold')

ax.grid(True, linestyle='--', alpha=0.6)

plt.tight_layout()
plt.savefig('mae_vs_epochs.tif', format='tiff', dpi=300, bbox_inches='tight')
plt.show()

plot_style = {
    'font.family': 'serif',
    'font.weight': 'bold'
}
plt.rcParams.update(plot_style)

mae_scaled = np.array(history.history['mae']) * 1000
val_mae_scaled = np.array(history.history['val_mae']) * 1000

fig, ax = plt.subplots(figsize=(20, 15))

ax.plot(mae_scaled, label='Training MAE', color='#1f77b4', linewidth=4)

ax.set_xlabel('Epochs', fontsize=44, fontweight='bold')
ax.set_ylabel('Mean Absolute Error (MAE) x $10^{-3}$', fontsize=44, fontweight='bold')
ax.tick_params(axis='both', which='major', labelsize=40)

legend = ax.legend(fontsize=32)
plt.setp(legend.get_title(), fontsize=34, fontweight='bold')

for label in (ax.get_xticklabels() + ax.get_yticklabels()):
    label.set_fontweight('bold')

ax.grid(True, linestyle='--', alpha=0.6)

plt.tight_layout()
plt.savefig('mae_vs_epochs_rescaled.tif', format='tiff', dpi=300, bbox_inches='tight')
plt.show()

plot_style = {
    'font.family': 'serif',
    'font.weight': 'bold'
}
plt.rcParams.update(plot_style)

fig, ax = plt.subplots(figsize=(20, 15))

ax.plot(history.history['mae'], label='Training MAE', color='#1f77b4', linewidth=4)

ax.set_xlabel('Epochs', fontsize=44, fontweight='bold')
ax.set_ylabel('Mean Absolute Error (MAE)', fontsize=44, fontweight='bold')
ax.tick_params(axis='both', which='major', labelsize=40)

legend = ax.legend(fontsize=32)
plt.setp(legend.get_title(), fontsize=34, fontweight='bold')

for label in (ax.get_xticklabels() + ax.get_yticklabels()):
    label.set_fontweight('bold')

ax.grid(True, linestyle='--', alpha=0.6)

plt.tight_layout()
plt.savefig('mae_vs_epochs_new.tif', format='tiff', dpi=300, bbox_inches='tight')
plt.show()

plot_style = {'font.family': 'serif', 'font.weight': 'bold'}
plt.rcParams.update(plot_style)

fig_stress, ax_stress = plt.subplots(figsize=(20, 15))
ax_stress.plot(mae_stress_unscaled, label='Training MAE', color='#1f77b4', linewidth=4)
ax_stress.set_title('Stress Prediction', fontsize=44, fontweight='bold')
ax_stress.set_xlabel('Epochs', fontsize=44, fontweight='bold')
ax_stress.set_ylabel('Mean Absolute Error (MPa)', fontsize=44, fontweight='bold')
ax_stress.tick_params(axis='both', which='major', labelsize=40)
legend_stress = ax_stress.legend(fontsize=32)
plt.setp(legend_stress.get_title(), fontsize=34, fontweight='bold')
for label in (ax_stress.get_xticklabels() + ax_stress.get_yticklabels()):
    label.set_fontweight('bold')
ax_stress.grid(True, linestyle='--', alpha=0.6)
plt.tight_layout()
plt.savefig('mae_vs_epochs_stress_unscaled.tif', format='tiff', dpi=300, bbox_inches='tight')
plt.show()

fig_strain, ax_strain = plt.subplots(figsize=(20, 15))
ax_strain.plot(mae_strain_unscaled, label='Training MAE', color='#2ca02c', linewidth=4)

ax_strain.set_title('Strain Prediction', fontsize=44, fontweight='bold')
ax_strain.set_xlabel('Epochs', fontsize=44, fontweight='bold')
ax_strain.set_ylabel('Mean Absolute Error (mm/mm)', fontsize=44, fontweight='bold')
ax_strain.tick_params(axis='both', which='major', labelsize=40)
legend_strain = ax_strain.legend(fontsize=32)
plt.setp(legend_strain.get_title(), fontsize=34, fontweight='bold')
for label in (ax_strain.get_xticklabels() + ax_strain.get_yticklabels()):
    label.set_fontweight('bold')
ax_strain.grid(True, linestyle='--', alpha=0.6)
plt.tight_layout()
plt.savefig('mae_vs_epochs_strain_unscaled.tif', format='tiff', dpi=300, bbox_inches='tight')
plt.show()

import matplotlib.pyplot as plt

plot_style = {'font.family': 'serif', 'font.weight': 'bold'}
plt.rcParams.update(plot_style)

fig, ax1 = plt.subplots(figsize=(20, 15))

# --- Left Axis (Stress) ---
color1 = '#1f77b4'
ax1.set_xlabel('Number of Epochs', fontsize=44, fontweight='bold')
ax1.set_ylabel('Stress MAE (MPa)', fontsize=44, fontweight='bold', color=color1)
ax1.plot(mae_stress_unscaled, color=color1, linestyle='-', linewidth=4, label='Stress')
ax1.tick_params(axis='y', labelcolor=color1, labelsize=40)
ax1.tick_params(axis='x', labelsize=40)

# --- Right Axis (Strain) ---
ax2 = ax1.twinx()

mae_strain_rescaled = mae_strain_unscaled * 1000
val_mae_strain_rescaled = val_mae_strain_unscaled * 1000

color2 = '#722F37'
ax2.set_ylabel('Strain MAE (x$10^{-3}$)', fontsize=44, fontweight='bold', color=color2)
ax2.plot(mae_strain_rescaled, color=color2, linestyle='-', linewidth=4, label='Strain')
ax2.tick_params(axis='y', labelcolor=color2, labelsize=40)

lines1, labels1 = ax1.get_legend_handles_labels()
lines2, labels2 = ax2.get_legend_handles_labels()
legend = ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper right', fontsize=32)
plt.setp(legend.get_title(), fontsize=34, fontweight='bold')

for label in (ax1.get_xticklabels() + ax1.get_yticklabels() + ax2.get_yticklabels()):
    label.set_fontweight('bold')

ax1.grid(True, linestyle='--', alpha=0.6)

plt.tight_layout(rect=[0, 0, 1, 0.98])
plt.savefig('mae_vs_epochs_dual_axis_rescaled.tif', format='tiff', dpi=300, bbox_inches='tight')
plt.show()

